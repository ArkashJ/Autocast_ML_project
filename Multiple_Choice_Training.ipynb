{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm",
      "gpuClass": "premium"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqGFzdkeAYuf"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"MultipleCorrect_CS542_CompetitionTesting.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1R2uTvKyoEHEBKpk-mW63CM20oKcPV_BR\n",
        "\"\"\"\n",
        "\n",
        "!pip install transformers datasets evaluate\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import DefaultDataCollator\n",
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "from huggingface_hub import notebook_login\n",
        "# from transformers import TFPegasusModel\n",
        "from transformers import pipeline\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import transformers\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "notebook_login()\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
        "\n",
        "\n",
        "autocast_questions = json.load(open('/content/drive/Shareddrives/Autocast Competition/autocast-master/autocast/autocast_questions.json'))\n",
        "test_questions = json.load(open('/content/drive/Shareddrives/Autocast Competition/autocast-master/competition/autocast_competition_test_set.json'))\n",
        "test_ids = [q['id'] for q in test_questions]\n",
        "\n",
        "mc_questions = [x for x in autocast_questions if x['qtype'] == 'mc' and x['id'] not in test_ids]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "divided_data = {}\n",
        "data = mc_questions\n",
        "for entry in data:\n",
        "    num_choices = len(entry[\"choices\"])\n",
        "    if num_choices is None:\n",
        "        continue\n",
        "    if num_choices not in divided_data:\n",
        "        divided_data[num_choices] = []\n",
        "    divided_data[num_choices].append(entry)\n",
        "\n",
        "# Save divided datasets into separate JSON files\n",
        "for num_choices, dataset in divided_data.items():\n",
        "    with open(f\"dataset_choices_{num_choices}.json\", \"w\") as f:\n",
        "        json.dump(dataset, f)"
      ],
      "metadata": {
        "id": "l-gIZWnFAikN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForMultipleChoice\n",
        "\n",
        "model = AutoModelForMultipleChoice.from_pretrained(\"roberta-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
      ],
      "metadata": {
        "id": "UaRAVpgoAisV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "from datasets import Dataset\n",
        "\n",
        "from transformers import RobertaTokenizer, RobertaForMultipleChoice, TrainingArguments, Trainer\n",
        "\n",
        "def preprocess_data(num_choices, dataset):\n",
        "    def format_example(example):\n",
        "        if not example[\"answer\"] or len(example[\"answer\"]) != 1:\n",
        "            return None\n",
        "\n",
        "        question = example[\"question\"]\n",
        "        choices = example[\"choices\"]\n",
        "        answer = ord(example[\"answer\"]) - ord(\"A\")\n",
        "\n",
        "        input_ids = []\n",
        "        attention_mask = []\n",
        "\n",
        "        for choice in choices:\n",
        "            encoded = tokenizer.encode_plus(question, choice, add_special_tokens=True,\n",
        "                                            max_length=512, padding=\"max_length\", truncation=True, return_attention_mask=True, return_tensors=\"pt\")\n",
        "            input_ids.append(encoded[\"input_ids\"])\n",
        "            attention_mask.append(encoded[\"attention_mask\"])\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"label\": answer\n",
        "        }\n",
        "\n",
        "    formatted_dataset = [format_example(example) for example in dataset]\n",
        "    formatted_dataset = [example for example in formatted_dataset if example is not None]\n",
        "    return Dataset.from_dict({k: [d[k] for d in formatted_dataset] for k in formatted_dataset[0]})\n"
      ],
      "metadata": {
        "id": "zTDyhg4cAivJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "1Em8A-c1Aixi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# newdataset = {}\n",
        "# newdataset[9] = divided_data[9]\n",
        "# newdataset[10] = divided_data[10]\n",
        "# newdataset[11] = divided_data[11]\n",
        "# newdataset[12] = divided_data[12]\n",
        "# newdataset[13] = divided_data[13]\n",
        "# newdataset[16] = divided_data[16]\n",
        "\n",
        "# newdataset.keys()"
      ],
      "metadata": {
        "id": "ze6pzS_xGSJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over divided datasets\n",
        "for num_choices, dataset in divided_data.items():\n",
        "    random.shuffle(dataset)\n",
        "    split_idx = int(0.8 * len(dataset))\n",
        "    train_dataset, eval_dataset = dataset[:split_idx], dataset[split_idx:]\n",
        "\n",
        "    # Preprocess the dataset\n",
        "    train_dataset = preprocess_data(num_choices, train_dataset)\n",
        "    eval_dataset = preprocess_data(num_choices, eval_dataset)\n",
        "\n",
        "    id2label = {i: chr(ord(\"A\") + i) for i in range(num_choices)}\n",
        "    label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "    # Initialize the tokenizer and the model\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "    model = RobertaForMultipleChoice.from_pretrained(\"roberta-base\"\n",
        "      , num_labels=num_choices, id2label=id2label, label2id=label2id)\n",
        "\n",
        "    # Set up training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"roberta_mc_model_{num_choices}\",\n",
        "        num_train_epochs=10,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        push_to_hub=True,\n",
        "        gradient_accumulation_steps=4,\n",
        "    )\n",
        "\n",
        "    # Initialize the Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # # Save the model\n",
        "    # trainer.save_model(f\"./model_choices_{num_choices}\")"
      ],
      "metadata": {
        "id": "zVm3xQ1WAi79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8F3-7tQFAi_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z3i9Iz3nAjBY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}